{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7b3afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import json\n",
    "from customEmbedding import CodetEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49826dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=projects)]\n",
      "<chromadb.api.client.Client object at 0x1311fffd0>\n",
      "name='projects' id=UUID('1b97bc17-d2b1-4db7-af96-5dcd73e0610e') metadata=None tenant='default_tenant' database='default_database'\n",
      "2244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "client = chromadb.PersistentClient(path='./db')\n",
    "print(client.list_collections())\n",
    "collection = client.list_collections()[0]\n",
    "print(client)\n",
    "print(collection)\n",
    "print(collection.count())\n",
    "\n",
    "ce = CodetEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6acc521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKING EMBED CALL FOR 1 DOCS\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "nl_query = \"get the params from the frontend and passes it to the stable diffusion model\"\n",
    "embedding = ce([nl_query])[0]\n",
    "print(len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c385ee83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969103217124939\n",
      "{\n",
      "  \"file_path\": \"modules/sd_models_xl.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"apply_model\",\n",
      "  \"id\": \"modules/sd_models_xl.py:apply_model\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"function_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 30,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"bc1aaf0ee5c7b1cc50146f91618afe212934630172144c607aeb8e21dc6c6ca0\"\n",
      "}\n",
      "def apply_model(self: sgm.models.diffusion.DiffusionEngine, x, t, cond):\n",
      "    return self.model(x, t, cond)\n",
      "\n",
      "1.0742220878601074\n",
      "{\n",
      "  \"file_path\": \"modules/esrgan_model.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"infer_params\",\n",
      "  \"id\": \"modules/esrgan_model.py:infer_params\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"function_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 264,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"f7badf78746033ba4b8cf622f7262d068356b700e9fd86335ab3bcca047903cc\"\n",
      "}\n",
      "def infer_params(state_dict):\n",
      "    # this code is copied from https://github.com/victorca25/iNNfer\n",
      "    scale2x = 0\n",
      "    scalemin = 6\n",
      "    n_uplayer = 0\n",
      "    plus = False\n",
      "\n",
      "    for block in list(state_dict):\n",
      "        parts = block.split(\".\")\n",
      "        n_parts = len(parts)\n",
      "        if n_parts == 5 and parts[2] == \"sub\":\n",
      "            nb = int(parts[3])\n",
      "        elif n_parts == 3:\n",
      "            part_num = int(parts[1])\n",
      "            if (part_num > scalemin\n",
      "                and parts[0] == \"model\"\n",
      "                and parts[2] == \"weight\"):\n",
      "                scale2x += 1\n",
      "            if part_num > n_uplayer:\n",
      "                n_uplayer = part_num\n",
      "                out_nc = state_dict[block].shape[0]\n",
      "        if not plus and \"conv1x1\" in block:\n",
      "            plus = True\n",
      "\n",
      "    nf = state_dict[\"model.0.weight\"].shape[0]\n",
      "    in_nc = state_dict[\"model.0.weight\"].shape[1]\n",
      "    out_nc = out_nc\n",
      "    scale = 2 ** scale2x\n",
      "\n",
      "    return in_nc, out_nc, nf, nb, plus, scale\n",
      "\n",
      "1.08198082447052\n",
      "{\n",
      "  \"file_path\": \"modules/sd_models.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"get_state_dict_from_checkpoint\",\n",
      "  \"id\": \"modules/sd_models.py:get_state_dict_from_checkpoint\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"function_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 176,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"ba9e009bb0474221fbb26adea97f85cf467ca7b1bb9203980021156fde5797cf\"\n",
      "}\n",
      "def get_state_dict_from_checkpoint(pl_sd):\n",
      "    pl_sd = pl_sd.pop(\"state_dict\", pl_sd)\n",
      "    pl_sd.pop(\"state_dict\", None)\n",
      "\n",
      "    is_sd2_turbo = 'conditioner.embedders.0.model.ln_final.weight' in pl_sd and pl_sd['conditioner.embedders.0.model.ln_final.weight'].size()[0] == 1024\n",
      "\n",
      "    sd = {}\n",
      "    for k, v in pl_sd.items():\n",
      "        if is_sd2_turbo:\n",
      "            new_key = transform_checkpoint_dict_key(k, checkpoint_dict_replacements_sd2_turbo)\n",
      "        else:\n",
      "            new_key = transform_checkpoint_dict_key(k, checkpoint_dict_replacements_sd1)\n",
      "\n",
      "        if new_key is not None:\n",
      "            sd[new_key] = v\n",
      "\n",
      "    pl_sd.clear()\n",
      "    pl_sd.update(sd)\n",
      "\n",
      "    return pl_sd\n",
      "\n",
      "1.0831553936004639\n",
      "{\n",
      "  \"file_path\": \"modules/models/diffusion/ddpm_edit.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"DiffusionWrapper\",\n",
      "  \"id\": \"modules/models/diffusion/ddpm_edit.py:DiffusionWrapper\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"class_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 299,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"d4857978a2f54a4719033e5eff9e8c1700502ee2c824c48bfbb8631eaf8200da\"\n",
      "}\n",
      "class DiffusionWrapper(pl.LightningModule):\n",
      "    def __init__(self, diff_model_config, conditioning_key):\n",
      "        super().__init__()\n",
      "        self.diffusion_model = instantiate_from_config(diff_model_config)\n",
      "        self.conditioning_key = conditioning_key\n",
      "        assert self.conditioning_key in [None, 'concat', 'crossattn', 'hybrid', 'adm']\n",
      "\n",
      "    def forward(self, x, t, c_concat: list = None, c_crossattn: list = None):\n",
      "        if self.conditioning_key is None:\n",
      "            out = self.diffusion_model(x, t)\n",
      "        elif self.conditioning_key == 'concat':\n",
      "            xc = torch.cat([x] + c_concat, dim=1)\n",
      "            out = self.diffusion_model(xc, t)\n",
      "        elif self.conditioning_key == 'crossattn':\n",
      "            cc = torch.cat(c_crossattn, 1)\n",
      "            out = self.diffusion_model(x, t, context=cc)\n",
      "        elif self.conditioning_key == 'hybrid':\n",
      "            xc = torch.cat([x] + c_concat, dim=1)\n",
      "            cc = torch.cat(c_crossattn, 1)\n",
      "            out = self.diffusion_model(xc, t, context=cc)\n",
      "        elif self.conditioning_key == 'adm':\n",
      "            cc = c_crossattn[0]\n",
      "            out = self.diffusion_model(x, t, y=cc)\n",
      "        else:\n",
      "            raise NotImplementedError()\n",
      "\n",
      "        return out\n",
      "\n",
      "1.1059248447418213\n",
      "{\n",
      "  \"file_path\": \"modules/sd_models.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"repair_config\",\n",
      "  \"id\": \"modules/sd_models.py:repair_config\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"function_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 246,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"0a736f97371501a99a563587b36391332ade01f6f6347c9754df84f90d6b9641\"\n",
      "}\n",
      "def repair_config(sd_config):\n",
      "\n",
      "    if not hasattr(sd_config.model.params, \"use_ema\"):\n",
      "        sd_config.model.params.use_ema = False\n",
      "\n",
      "    if hasattr(sd_config.model.params, 'unet_config'):\n",
      "        if shared.cmd_opts.no_half:\n",
      "            sd_config.model.params.unet_config.params.use_fp16 = False\n",
      "        elif shared.cmd_opts.upcast_sampling:\n",
      "            sd_config.model.params.unet_config.params.use_fp16 = True\n",
      "\n",
      "    if getattr(sd_config.model.params.first_stage_config.params.ddconfig, \"attn_type\", None) == \"vanilla-xformers\" and not shared.xformers_available:\n",
      "        sd_config.model.params.first_stage_config.params.ddconfig.attn_type = \"vanilla\"\n",
      "\n",
      "    # For UnCLIP-L, override the hardcoded karlo directory\n",
      "    if hasattr(sd_config.model.params, \"noise_aug_config\") and hasattr(sd_config.model.params.noise_aug_config.params, \"clip_stats_path\"):\n",
      "        karlo_path = os.path.join(paths.models_path, 'karlo')\n",
      "        sd_config.model.params.noise_aug_config.params.clip_stats_path = sd_config.model.params.noise_aug_config.params.clip_stats_path.replace(\"checkpoints/karlo_models\", karlo_path)\n",
      "\n",
      "1.1457583904266357\n",
      "{\n",
      "  \"file_path\": \"modules/sd_hijack_optimizations.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"SdOptimization\",\n",
      "  \"id\": \"modules/sd_hijack_optimizations.py:SdOptimization\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"class_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 174,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"c6db2d3337dcec041ab46f9d5d0a53b2f8d98cf2adc195d196e25ecc7f138685\"\n",
      "}\n",
      "class SdOptimization:\n",
      "    name: str = None\n",
      "    label: str | None = None\n",
      "    cmd_opt: str | None = None\n",
      "    priority: int = 0\n",
      "\n",
      "    def title(self):\n",
      "        if self.label is None:\n",
      "            return self.name\n",
      "\n",
      "        return f\"{self.name} - {self.label}\"\n",
      "\n",
      "    def is_available(self):\n",
      "        return True\n",
      "\n",
      "    def apply(self):\n",
      "        pass\n",
      "\n",
      "    def undo(self):\n",
      "        ldm.modules.attention.CrossAttention.forward = hypernetwork.attention_CrossAttention_forward\n",
      "        ldm.modules.diffusionmodules.model.AttnBlock.forward = diffusionmodules_model_AttnBlock_forward\n",
      "\n",
      "        sgm.modules.attention.CrossAttention.forward = hypernetwork.attention_CrossAttention_forward\n",
      "        sgm.modules.diffusionmodules.model.AttnBlock.forward = sgm_diffusionmodules_model_AttnBlock_forward\n",
      "\n",
      "1.1488380432128906\n",
      "{\n",
      "  \"file_path\": \"modules/sd_models_config.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"guess_model_config_from_state_dict\",\n",
      "  \"id\": \"modules/sd_models_config.py:guess_model_config_from_state_dict\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"function_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 428,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"3ceeebd5688263ba435ff5aa2742bc9334f2470f2e9f631cd0d559ef97e9caef\"\n",
      "}\n",
      "def guess_model_config_from_state_dict(sd, filename):\n",
      "    sd2_cond_proj_weight = sd.get('cond_stage_model.model.transformer.resblocks.0.attn.in_proj_weight', None)\n",
      "    diffusion_model_input = sd.get('model.diffusion_model.input_blocks.0.0.weight', None)\n",
      "    sd2_variations_weight = sd.get('embedder.model.ln_final.weight', None)\n",
      "\n",
      "    if sd.get('conditioner.embedders.1.model.ln_final.weight', None) is not None:\n",
      "        return config_sdxl\n",
      "    if sd.get('conditioner.embedders.0.model.ln_final.weight', None) is not None:\n",
      "        return config_sdxl_refiner\n",
      "    elif sd.get('depth_model.model.pretrained.act_postprocess3.0.project.0.bias', None) is not None:\n",
      "        return config_depth_model\n",
      "    elif sd2_variations_weight is not None and sd2_variations_weight.shape[0] == 768:\n",
      "        return config_unclip\n",
      "    elif sd2_variations_weight is not None and sd2_variations_weight.shape[0] == 1024:\n",
      "        return config_unopenclip\n",
      "\n",
      "    if sd2_cond_proj_weight is not None and sd2_cond_proj_weight.shape[1] == 1024:\n",
      "        if diffusion_model_input.shape[1] == 9:\n",
      "            return config_sd2_inpainting\n",
      "        elif is_using_v_parameterization_for_sd2(sd):\n",
      "            return config_sd2v\n",
      "        else:\n",
      "            return config_sd2\n",
      "\n",
      "    if diffusion_model_input is not None:\n",
      "        if diffusion_model_input.shape[1] == 9:\n",
      "            return config_inpainting\n",
      "        if diffusion_model_input.shape[1] == 8:\n",
      "            return config_instruct_pix2pix\n",
      "\n",
      "\n",
      "    if sd.get('cond_stage_model.roberta.embeddings.word_embeddings.weight', None) is not None:\n",
      "        if sd.get('cond_stage_model.transformation.weight').size()[0] == 1024:\n",
      "            return config_alt_diffusion_m18\n",
      "        return config_alt_diffusion\n",
      "\n",
      "    return config_default\n",
      "\n",
      "1.1517082452774048\n",
      "{\n",
      "  \"file_path\": \"extensions-builtin/LDSR/sd_hijack_ddpm_v1.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"DiffusionWrapperV1\",\n",
      "  \"id\": \"extensions-builtin/LDSR/sd_hijack_ddpm_v1.py:DiffusionWrapperV1\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"class_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 301,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"5bf96f1a215d826ed629c203f73de4f1a2a8f2c56df079e52aeedea9565fa8be\"\n",
      "}\n",
      "class DiffusionWrapperV1(pl.LightningModule):\n",
      "    def __init__(self, diff_model_config, conditioning_key):\n",
      "        super().__init__()\n",
      "        self.diffusion_model = instantiate_from_config(diff_model_config)\n",
      "        self.conditioning_key = conditioning_key\n",
      "        assert self.conditioning_key in [None, 'concat', 'crossattn', 'hybrid', 'adm']\n",
      "\n",
      "    def forward(self, x, t, c_concat: list = None, c_crossattn: list = None):\n",
      "        if self.conditioning_key is None:\n",
      "            out = self.diffusion_model(x, t)\n",
      "        elif self.conditioning_key == 'concat':\n",
      "            xc = torch.cat([x] + c_concat, dim=1)\n",
      "            out = self.diffusion_model(xc, t)\n",
      "        elif self.conditioning_key == 'crossattn':\n",
      "            cc = torch.cat(c_crossattn, 1)\n",
      "            out = self.diffusion_model(x, t, context=cc)\n",
      "        elif self.conditioning_key == 'hybrid':\n",
      "            xc = torch.cat([x] + c_concat, dim=1)\n",
      "            cc = torch.cat(c_crossattn, 1)\n",
      "            out = self.diffusion_model(xc, t, context=cc)\n",
      "        elif self.conditioning_key == 'adm':\n",
      "            cc = c_crossattn[0]\n",
      "            out = self.diffusion_model(x, t, y=cc)\n",
      "        else:\n",
      "            raise NotImplementedError()\n",
      "\n",
      "        return out\n",
      "\n",
      "1.1592721939086914\n",
      "{\n",
      "  \"file_path\": \"modules/sd_samplers_timesteps.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"CompVisTimestepsDenoiser\",\n",
      "  \"id\": \"modules/sd_samplers_timesteps.py:CompVisTimestepsDenoiser\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"class_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 72,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"9146e89c63b54c4530cd966bc597712453da32ba17679e7edbee901c4ecf5715\"\n",
      "}\n",
      "class CompVisTimestepsDenoiser(torch.nn.Module):\n",
      "    def __init__(self, model, *args, **kwargs):\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.inner_model = model\n",
      "\n",
      "    def forward(self, input, timesteps, **kwargs):\n",
      "        return self.inner_model.apply_model(input, timesteps, **kwargs)\n",
      "\n",
      "1.1632272005081177\n",
      "{\n",
      "  \"file_path\": \"modules/sd_hijack_unet.py\",\n",
      "  \"file_type\": \"py\",\n",
      "  \"function_name\": \"apply_model\",\n",
      "  \"id\": \"modules/sd_hijack_unet.py:apply_model\",\n",
      "  \"is_chunked\": false,\n",
      "  \"node_type\": \"function_definition\",\n",
      "  \"project\": \"projects/stable-diffusion-webui\",\n",
      "  \"token_count\": 138,\n",
      "  \"type\": \"function\",\n",
      "  \"unique_id\": \"47b50d33a80e7e6fa03e898bab9abf0a134e26fdbb7a049effa0d893974a3121\"\n",
      "}\n",
      "def apply_model(orig_func, self, x_noisy, t, cond, **kwargs):\n",
      "\n",
      "    if isinstance(cond, dict):\n",
      "        for y in cond.keys():\n",
      "            if isinstance(cond[y], list):\n",
      "                cond[y] = [x.to(devices.dtype_unet) if isinstance(x, torch.Tensor) else x for x in cond[y]]\n",
      "            else:\n",
      "                cond[y] = cond[y].to(devices.dtype_unet) if isinstance(cond[y], torch.Tensor) else cond[y]\n",
      "\n",
      "    with devices.autocast():\n",
      "        return orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs).float()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results = collection.get(\n",
    "#     limit=10,\n",
    "#     where={\"type\": \"file\"},\n",
    "#     include=['embeddings', 'metadatas']\n",
    "# )\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=embedding,\n",
    "    include=['documents', 'distances', 'metadatas', 'embeddings']\n",
    ")\n",
    "# print(results['distances'])\n",
    "# print([len(e) for e in results['embeddings'][0]])\n",
    "for dist, m, doc in zip(results['distances'][0], results['metadatas'][0], results['documents'][0]):\n",
    "    print(dist)\n",
    "    print(json.dumps(m, indent=2))\n",
    "    print(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b2e1c7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# dir(collection)\n",
    "result = collection._embed(['this is a test'])[0]\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de43a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
